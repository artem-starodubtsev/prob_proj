{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T23:54:04.745354Z",
     "start_time": "2025-12-14T23:54:04.741053Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches"
   ],
   "outputs": [],
   "execution_count": 376
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T23:54:04.763158Z",
     "start_time": "2025-12-14T23:54:04.748420Z"
    }
   },
   "source": [
    "#np.random.seed(123)"
   ],
   "outputs": [],
   "execution_count": 377
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ln_22CuSFwEg"
   },
   "source": [
    "# Hidden Markov Model Assignment\n",
    "\n",
    "The robot can move on the cells with light background, but cannot go over the obstacles, which have the dark blue background."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Maze definition\n",
    "\n",
    "Here we define the robot’s environment as a 2D NumPy array.\n",
    "- Each **1** represents a feasible cell where the robot can be.\n",
    "- Each **0** represents an obstacle where the robot cannot move which can be called blocks or Unreachable.\n",
    "\n",
    "This maze will be the basis for defining the states and transitions of the HMM.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Use the maze corresponding to your group!\n",
    "maze = np.array([\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0],\n",
    "    [0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1],\n",
    "    [0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
    "    [1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0],\n",
    "])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Visualizing the maze\n",
    "\n",
    "The function `plot_maze` helps us in rawing of the  maze as a grid:\n",
    "- Feasible cells are light blue.\n",
    "- Obstacles or Blocks are dark blue.\n",
    "- Each cell gets a unique index, which we use later to map positions to HMM states.\n",
    "- Optionally, a given trajectory `Z` can be highlighted in red.\n",
    "\n",
    "This visualization helps to understand how states relate to physical positions.\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def plot_maze(ax, maze, skip_walls=True, Z=None):\n",
    "    cell_idx = 0\n",
    "    rows, cols = maze.shape\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            color = 'lightblue' if maze[r, c] == 1 else 'blue'\n",
    "\n",
    "            if Z is not None and (r * cols + c) in Z:\n",
    "                color = 'red'\n",
    "\n",
    "            ax.add_patch(patches.Rectangle((c, rows - 1 - r), 1, 1, edgecolor='black', facecolor=color))\n",
    "            if maze[r, c] == 1 or not skip_walls:\n",
    "                ax.text(c + 0.5, rows - 1 - r + 0.5, str(cell_idx), color='black', ha='center', va='center',\n",
    "                        fontsize=14)\n",
    "            cell_idx += 1\n",
    "\n",
    "    ax.set_xlim(0, cols)\n",
    "    ax.set_ylim(0, rows)\n",
    "\n",
    "    ax.set_aspect('equal')\n",
    "    ax.axis('off')\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 9))\n",
    "\n",
    "plot_maze(ax, maze)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Defintion of the states\n",
    "the states are a list of all the posssibile cells (rows, columns)which are flessibile of thr maze matrix / grid , which the robot can naigate through."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Suggested names for possible states\n",
    "rows, cols = maze.shape\n",
    "states = [(r, c) for r in range(rows) for c in range(cols) if maze[r, c]]"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Observation vocabulary\n",
    " Suggested names for the possible observations.The robot’s sensor reads which directions (N, S, E, W) are feasible from the current cell.\n",
    "There are \\(2^4 = 16\\) possible combinations, so we build a **vocabulary** of 16 observation symbols:\n",
    "\n",
    "- Each symbol corresponds to a 4-bit pattern (N, S, E, W).\n",
    "- For example, (NE) means “North and East are free; South and West are blocked”."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Suggested names for the possible observations. If can be seen as a binary digit from 0 to 15, where the least significant bit indicates West.\n",
    "# This may be usefule to code the emission matrix\n",
    "letters = ['N', 'S', 'E', 'W']\n",
    "vocabulary = []\n",
    "for i in range(2 ** len(letters)):  # observations can be indexed with numbers 0 to 15\n",
    "    binary = format(i, '04b')  # 4-bit format interpreted as possibility to move N,S,E,W\n",
    "    combination = ''.join([letters[j] for j in range(4) if binary[j] == '1'])\n",
    "    combination = '(' + combination + ')'\n",
    "    vocabulary.append(combination)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "vocabulary"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1 HMM Definition and Trajectory Generation"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1.1 Transition probability definition\n",
    "\n",
    "Define the *transition probability matrix* $A$ corresponding to the robot maze. Consider that:\n",
    "\n",
    "* The robot can only reach a neighboring cell.\n",
    "* The robot can move North, South, East, West.\n",
    "* Diagonal moves are not allowed.\n",
    "* Passing over obstacles is not allowed.\n",
    "* Feasible transitions are equally probable."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def create_path_matrix(maze):\n",
    "    rows, cols = maze.shape\n",
    "    f_len = rows * cols\n",
    "    A = np.zeros((f_len, f_len))\n",
    "    B = np.zeros((f_len, 2 ** len(letters)))\n",
    "\n",
    "    arr = maze.flatten()\n",
    "\n",
    "    # N,S,E,W\n",
    "    for i in range(f_len):\n",
    "        code = 0\n",
    "        if arr[i] == 0:\n",
    "            continue\n",
    "        if (i + 1) % cols and arr[i + 1] == 1:  # E\n",
    "            A[i, i + 1] = 1\n",
    "            code += 2\n",
    "        if i % cols and arr[i - 1] == 1:  # W\n",
    "            A[i, i - 1] = 1\n",
    "            code += 1\n",
    "        if i + cols < f_len and arr[i + cols] == 1:  # S\n",
    "            A[i, i + cols] = 1\n",
    "            code += 4\n",
    "        if i - cols >= 0 and arr[i - cols] == 1:  # N\n",
    "            A[i, i - cols] = 1\n",
    "            code += 8\n",
    "        B[i][code] = 1\n",
    "        pths = A[i, :].sum()\n",
    "        if pths != 0:\n",
    "            A[i, :] = A[i, :] / pths\n",
    "    return A, B"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "A, B = create_path_matrix(maze)\n",
    "print(A.shape)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "**A)** Transition matrix A:\n",
    "    What next state is possible from here? (movement)\n",
    "Basically the transistion matrix helps to tells us in what  state the  robot is in ,what the % chance to move a flessibile cell(state).\n",
    "So the transistion matrix is made up of the entire states of the maze  but of flessible states & states which are flessible.\n",
    "\n",
    "**B)** Emission matrix B:\n",
    "    What observation is likely from this state? (sensor)\n",
    "\n",
    "Emission matrix  helps to tell what is the likely observation  y , when  the robot is in a state .\n",
    "Row = state  , column = observations\n",
    "\n",
    "B[i,y] = probability that the sensor returns observation y when the robot is in state i.\n",
    "\n",
    "\n",
    "There are 16 possible observations because:\n",
    " * they are 4 directions  -> each be  0 or 1 => 2^4 = 16\n",
    "\n",
    "So the emission  matrix B  would have a size of  number of states  x 16 (number of observation)\n",
    "\n",
    "Additional info : ```arr = maze.flatten()```\n",
    "helps to turn the maze into a single array.\n",
    "\n",
    "So code is an integer from 0 to 15 that encodes which directions are open.\n",
    "\n",
    "```pths``` counts how many outgoing neighbors exist from state i , if  at least one neighbours exist  we dived the row by pths , this makes all outgoing transitions to have a equal likely probability  over the neighbours\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1.2 Emission probability definition\n",
    "\n",
    "Define the *emission probability matrix* $B$.\n",
    "* After each move, the robot senses whether the cells to the North, South, East, West are feasible.\n",
    "* There are 16 possible observations (previously defined variable `vocabulary`)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(B.shape)\n",
    "print(B)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.3 Trajectory Sampling"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Sample and visualize a state and observation sequences $Z$ and $Y$ of\n",
    "length $T = 20$ compatible with the previous hypotheses.\n",
    "\n",
    "* Use the previously defined transition and emission matrices\n",
    "* Consider the initial position equiprobable among the admissible states"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "So since the robot have an equal probability of starting any  cell in the intital  case / start , for probability calculations. We then count the number of feasible cells (cells with value 1) in the entire maze. Then we normalize the start_prob matrix by dividing each element by the total number of feasible cells. This ensures that the sum of all probabilities in the start_prob matrix equals 1, making it a valid probability distribution over the entire grid."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "start_prob = maze.copy()\n",
    "start_prob = start_prob / start_prob.sum()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def pick_random_start(start_prob):\n",
    "    array = start_prob.flatten()\n",
    "    return np.random.choice(range(len(array)), p=array)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "t = 20\n",
    "Z = np.zeros(t, dtype=int)\n",
    "Y = np.zeros(t, dtype=int)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "Z[0] = pick_random_start(start_prob)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "A) Traverse the state sequence Z according to the transition matrix A.\n",
    "for each time step i from 1 to t-1:\n",
    "* We look at the previous state Z[i-1]\n",
    "* Use the correspondind row of the transistion matrix A A[Z[i-1]] to iterate (sample) over to the next state\n",
    "* Then we store in the Z[i] the sampled state\n",
    "\n",
    "B)The observation matrix Y is built according to the emission matrix B.\n",
    "* These numbers go from 0 to 15.\n",
    "* Use row B[Z[i]] as the emission distribution to sample an observation.\n",
    "\n",
    "* Store in Y[i], which tells what sensors is read at that cell  , this helps us  tell which direction (vocabulary ) around is  free for  movement.."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def traverse_z(Z, A):\n",
    "    for i in range(1, t):\n",
    "        Z[i] = np.random.choice(range(A.shape[0]), p=A[Z[i - 1]])\n",
    "\n",
    "\n",
    "def build_y(Z, Y, B):\n",
    "    for i in range(t):\n",
    "        Y[i] = np.random.choice(range(16), p=B[Z[i]])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "traverse_z(Z, A)\n",
    "print(Z)\n",
    "build_y(Z, Y, B)\n",
    "print(Y)\n",
    "print(list(map(vocabulary.__getitem__, Y)))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 9))\n",
    "plot_maze(ax, maze, Z=Z)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2 Decoding and inference"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.1 Likelihood\n",
    "1\n",
    "Compute the likelihood of the obtained observation sequence $Y$."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def likelihood_calc(A, B, Y, pi):\n",
    "    alpha = np.zeros((len(Y), len(B)))\n",
    "    alpha[0] = pi.flatten() * B[:, Y[0]]\n",
    "    for t in range(1, len(Y)):\n",
    "        alpha[t] = B[:, Y[t]] * (alpha[t - 1] @ A)\n",
    "    return alpha, alpha[-1].sum()\n",
    "\n",
    "\n",
    "alpha, likelihood = likelihood_calc(A, B, Y, start_prob)\n",
    "likelihood"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "To create the likelihood calculation ,alpha matrix which helps store our forward probabilities (of our HMM )at each time step for each state, it should have shape T x N (N = length of B). So now we are going to apply the formula seem in class : **Initialization: α₁(j) = πⱼ bⱼ(y₁)** , then in the second block with loop we apply recursive formula : **αₜ(j) = Σᵢ₌₁ᴺ αₜ₋₁(i) aᵢⱼ bⱼ(yₜ)**\n",
    "then lastly in  the output ``` alpha[-1].sum()``` : the total likelihood  P(Y), the sum of all alpha[T-1, j] which basically the  application this formula **P(Y) = Σᵢ₌₁ᴺ α_T(i)**.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.1 Decoding \n",
    "\n",
    "Obtain the most probable state sequence, given the observation sequence $Y$.We will consider the *decoding* problem for HMMs, i.e., given a sequence of observations $Y = y_1, \\ldots, y_T$, we want to find the most probable sequence of hidden states $Z = z_1, \\ldots, z_T$ that could have generated the observations. In particular, we want to find\n",
    "\n",
    "$$ \\hat Z = \\arg \\max_Z P(Z \\mid Y) $$\n",
    "\n",
    "In the maze localization problem:\n",
    "- States $z_t$ represent the robot's **true cell positions**\n",
    "- Observations $y_t$ represent **sensor readings** (open directions)\n",
    "- The goal is to infer the **single most probable path** of the robot"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def viterbi(A, B, Y, pi):\n",
    "    v = np.zeros((len(Y), len(B)))\n",
    "    back = np.zeros((len(Y), len(B)), dtype=int)\n",
    "    v[0] = pi.flatten() * B[:, Y[0]]\n",
    "    back[0].fill(-1)\n",
    "\n",
    "    for t in range(1, len(Y)):\n",
    "        for j in range(len(B)):\n",
    "            scores = v[t - 1] * A[:, j]\n",
    "            best_prev = np.argmax(scores)\n",
    "            v[t][j] = B[j][Y[t]] * scores[best_prev]\n",
    "            back[t][j] = best_prev\n",
    "\n",
    "    path = np.zeros(len(Y), dtype=int)\n",
    "    path[-1] = np.argmax(v[-1])\n",
    "\n",
    "    for i in range(len(Y) - 2, -1, -1):\n",
    "        path[i] = back[i + 1][path[i + 1]]\n",
    "\n",
    "    return v, path\n",
    "\n",
    "\n",
    "v, path = viterbi(A, B, Y, start_prob)\n",
    "\n",
    "print(path, 'most possible path')\n",
    "print(Z, 'actual path')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This function implements the Viterbi algorithm to find the most probable sequence of hidden states (path) given an observation sequence \\(Y\\). The algorithm uses dynamic programming to efficiently compute the highest probability of any path that ends in each state at each time step.\n",
    "The function initializes two matrices: `v` for storing the maximum probabilities and `back` for backtracking the most probable path. At first initializes the first column of `v` using the initial state distribution \\(pi\\) and the emission probabilities for the first observation. Secondly set of nested loops iteratively fills in the `v` and `back` matrices by calculating the maximum probability of reaching each state at each time step, considering all possible previous states.\n",
    "After filling in the matrices, the function backtracks from the last time step to reconstruct the most probable path of states."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Formulars applied from class\n",
    "#### Viterbi recursion\n",
    "\n",
    "Define the Viterbi score:$$v_t(j) = \\max_{z_0,\\dots,z_{t-1}} P(z_0,\\dots,z_{t-1}, z_t=j, y_0,\\dots,y_t)$$\n",
    "**Initialization ($t=0$):** $$ v_0(j) = \\pi(j)\\,B[j, y_0] $$\n",
    "**Recursion ($t \\ge 1$):** $$ v_t(j) = B[j, y_t] \\cdot \\max_i \\left( v_{t-1}(i)\\,A[i,j] \\right)$$\n",
    "**Backpointer:** $$\\text{back}_t(j) = \\arg\\max_i \\left( v_{t-1}(i)\\,A[i,j] \\right) $$\n",
    "\n",
    "#### Path reconstruction (backtracking)\n",
    "\n",
    "1) Final state: $$ z_T^* = \\arg\\max_j v_T(j) $$\n",
    "\n",
    "2) Backtrack for $t = T-1, \\dots, 1$:\n",
    "$$ z_{t-1}^* = \\text{back}_t(z_t^*) $$\n",
    "This yields the most likely hidden state sequence $(z_0^*, z_1^*, \\dots, z_T^*)$.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Final\n",
    "\n",
    "At each time step, for each candidate state $j$, Viterbi:\n",
    "1. considers all possible previous states $i$\n",
    "2. keeps only the best incoming path (the max over $i$)\n",
    "3. multiplies by the observation likelihood $B[j, y_t]$\n",
    "\n",
    "In the noiseless sensor case, $B[j,y_t]$ is typically 0 or 1:\n",
    "- if the observation matches state $j$, the path survives\n",
    "- otherwise the probability becomes 0 and the state is eliminated"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.2 Filtering\n",
    "\n",
    "Obtain the filtering distribution $P(z_t \\mid y_{1:t})$ at each time step $t$."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def filtering(A, B, Y, pi):\n",
    "    alpha, _ = likelihood_calc(A, B, Y, pi)\n",
    "    return alpha / alpha.sum(axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "props_t = filtering(A, B, Y, start_prob)\n",
    "props_t"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The filtering is used to compute the posterior distribution over the hidden states at each time step, given all observations up to that time. The function `filtering` first computes the forward probabilities (α alpha) using the `likelihood_calc` function. Then, it normalizes these probabilities row-wise to obtain valid probability distributions for each time step. The normalization, ensures that each row of the resulting matrix sums to 1. The output `props_t` contains the filtering distributions $P(z_t \\mid y_{0:t})$ for each time step (t).\n",
    "\n",
    "* It estimates **where the robot is now**, given all past sensor readings\n",
    "* It maintains uncertainty instead of selecting a single path\n",
    "\n",
    "In conclusion filtering helps us  estimate the probability ditribution of the curent state of our robot , through the use of looking at previous states it , therefore keeps all possible states with their probabilities instead of just picking the most likely state like in viterbi algorithm."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.3 Noisy observations\n",
    "\n",
    "Repeat steps 2.1 and 2.2 in the presence of sensor error noise. In particular, consider that:\n",
    "  * With probability $1-\\epsilon$, the sensor provides the correct reading\n",
    "  * With probability $\\epsilon$, the sensor returns a wrong reading. \n",
    "  * The $\\epsilon$ probability is equally split among all wrong readings.\n",
    "  * Set $\\epsilon=0.2$. Optionally, test also other values."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "####  Noisy sensor model\n",
    "\n",
    "We asked to include the sensor noise into the emission matrix,then we built a new emission matrix B called B_noisy and then:\n",
    "* Sample a new noisy observation sequence Y_noisy.\n",
    "* Recompute the likelihood, Viterbi path, and filtering distributions under this noisy model.\n",
    "* Compare the inferred path with the true state sequence (Z).\n",
    "\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "esp = 0.1\n",
    "\n",
    "B_noisy = np.zeros_like(B)\n",
    "for i in range(0, len(B)):\n",
    "    B_noisy[i] = np.array(\n",
    "        [esp / (len(vocabulary) - 1) if j != np.argmax(B[i]) else 1 - esp for j in range(len(vocabulary))])\n",
    "\n",
    "print(Z, 'actual path')\n",
    "Y_noisy = np.zeros(t, dtype=int)\n",
    "build_y(Z, Y_noisy, B_noisy)\n",
    "print(Y_noisy, 'noisy sensory data')\n",
    "print(Y, 'actual sensory data')\n",
    "print(list(map(vocabulary.__getitem__, Y_noisy)))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 9))\n",
    "plot_maze(ax, maze, Z=Z)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "alpha, likelihood = likelihood_calc(A, B_noisy, Y_noisy, start_prob)\n",
    "likelihood"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "v, path = viterbi(A, B_noisy, Y_noisy, start_prob)\n",
    "\n",
    "print(path, 'possible noisy path')\n",
    "print(Z, 'actual path')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "props_t = filtering(A, B_noisy, Y_noisy, start_prob)\n",
    "props_t"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "where we tried these values of noises :\n",
    "$\\epsilon_1=0.2$ , $\\epsilon_2=0.1$\n",
    "We first tried noise at $\\epsilon_1=0.2$ but it was too high and the results were not good for the possible path found but thanks to this we discovered that lowering the noise to 0.1($epsilon_2$) gave us better results and the noisy path was now closer to our actual path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Analysis and discussion\n",
    "\n",
    "Comment the techniques applied and the obtained results."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This project applied a Hidden Markov Model (HMM) to robot localization in a grid maze, implementing the three core inference tasks studied in class: likelihood computation (Forward), decoding (Viterbi), and online state estimation (filtering).\n",
    "The transition model encoded the maze geometry by allowing only physically feasible moves, ensuring that inferred trajectories were always consistent with the environment. The emission model strongly constrained the state space in the noise-free case, leading to rapid uncertainty reduction. When sensor noise was introduced (ε1 = 0.2 , ε1 = 0.1), the robot becomes less sure about where it is. The observation likelihoods decreased and sensor reading can now match several different positions, not just one. So now the model assigns smaller probabilities to each position and spreads its belief over many possible locations instead of focusing on a single one.\n",
    "Viterbi decoding produced a physically plausible trajectory closely matching the true path, with minor errors when different locations in the maze look identical to the sensors. When this happens, the algorithm can choose the wrong position even though it is still a valid move.\n",
    "Filtering complemented this by providing full belief distributions, explicitly revealing uncertainty, especially under noisy sensing.\n",
    "Overall, the results highlight the effectiveness of probabilistic HMM inference for localization and demonstrate why probabilistic reasoning is essential for robust operation in the presence of sensor noise.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Conclusion\n",
    "\n",
    "The implementation demonstrates that HMMs provide a principled approach to sequential inference in robotics. Forward enables efficient likelihood computation, Viterbi yields a globally consistent best path, and filtering provides an interpretable measure of uncertainty over time. The contrast between noise-free and ε1=0.2 & ε1=0.1  noisy sensing highlights the importance of probabilistic reasoning in realistic scenarios."
   ],
   "attachments": {
    "0091fee8-493f-419d-985d-c9023df37c33.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7UAAAD6CAIAAADx3fdGAAACyUlEQVR4Xu3BAQ0AAADCoPdPbQ43oAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgDcD3dYAAdxTfAkAAAAASUVORK5CYII="
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at ```report.pdf```"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
